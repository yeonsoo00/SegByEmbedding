{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2patch = \"/home/yec23006/projects/research/KneeGrowthPlate/Embedding/results/patch_extraction/filtered_patches_nb.npy\"\n",
    "path2patchposition = \"/home/yec23006/projects/research/KneeGrowthPlate/Embedding/results/patch_extraction/filtered_patch_positions_nb.npy\"\n",
    "path2prediction = \"/home/yec23006/projects/research/KneeGrowthPlate/Embedding/results/patch_extraction/predicted_labels.npy\"\n",
    "path2img = '/home/yec23006/projects/research/KneeGrowthPlate/Knee_GrowthPlate/Images/CCC_K05_hK_FL1_s1_shift3_So.jpg'\n",
    "\n",
    "patch = np.load(path2patch)\n",
    "patchposition = np.load(path2patchposition)\n",
    "prediction = np.load(path2prediction)\n",
    "image = cv2.cvtColor(cv2.imread(path2img, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_patch_labels(image_shape, patch_size, positions, labels):\n",
    "    \"\"\"\n",
    "    Ensures that the blue (0) area remains connected by:\n",
    "      1. Converting isolated red (1) patches to blue if surrounded by blue.\n",
    "      2. Ensuring all blue regions are connected using connected components.\n",
    "\n",
    "    Args:\n",
    "        image_shape (tuple): Shape of the original image (H, W, C).\n",
    "        patch_size (int): The size of the patches.\n",
    "        positions (np.array): List of (y, x) positions of each patch.\n",
    "        labels (np.array): Patch classification labels (1: blue, 0: red).\n",
    "\n",
    "    Returns:\n",
    "        np.array: Updated labels with connected blue patches.\n",
    "    \"\"\"\n",
    "    h, w, _ = image_shape\n",
    "    \n",
    "    # Create a grid to store patch labels\n",
    "    grid_h, grid_w = h // patch_size, w // patch_size\n",
    "    grid = np.full((grid_h, grid_w), -1, dtype=int)\n",
    "    \n",
    "    # Map positions to the grid\n",
    "    pos_to_index = {}\n",
    "    for idx, ((y, x), label) in enumerate(zip(positions, labels)):\n",
    "        grid_y, grid_x = y // patch_size, x // patch_size\n",
    "        grid[grid_y, grid_x] = label\n",
    "        pos_to_index[(grid_y, grid_x)] = idx  # Store index for updates later\n",
    "\n",
    "    # --- Step 1: Convert isolated red patches to blue ---\n",
    "    refined_labels = labels.copy()\n",
    "    offsets = [(-1, 0), (1, 0), (0, -1), (0, 1)]  # 4-neighborhood\n",
    "\n",
    "    for i, ((y, x), label) in enumerate(zip(positions, labels)):\n",
    "        if label == 0:  # Check only red patches\n",
    "            grid_y, grid_x = y // patch_size, x // patch_size\n",
    "            surrounding_blue_count = 0\n",
    "            total_neighbors = 0\n",
    "            \n",
    "            for dy, dx in offsets:\n",
    "                ny, nx = grid_y + dy, grid_x + dx\n",
    "                if 0 <= ny < grid.shape[0] and 0 <= nx < grid.shape[1]:  # Valid index\n",
    "                    total_neighbors += 1\n",
    "                    if grid[ny, nx] == 0:\n",
    "                        surrounding_blue_count += 1\n",
    "\n",
    "            # Convert red to blue if mostly surrounded by blue\n",
    "            if total_neighbors > 0 and (surrounding_blue_count / total_neighbors) > 0.7:\n",
    "                refined_labels[i] = 0\n",
    "                grid[grid_y, grid_x] = 0  # Update grid too\n",
    "\n",
    "    # --- Step 2: Ensure Blue Area is Connected ---\n",
    "    # Label connected blue components\n",
    "    blue_mask = (grid == 1).astype(np.uint8)\n",
    "    num_labels, labeled_grid = cv2.connectedComponents(blue_mask, connectivity=4)\n",
    "\n",
    "    # Find the largest blue component\n",
    "    component_sizes = np.bincount(labeled_grid.ravel())[1:]  # Ignore background (0)\n",
    "    if len(component_sizes) > 0:\n",
    "        largest_blue_label = np.argmax(component_sizes) + 1  # Largest blue component\n",
    "\n",
    "        # Convert smaller blue components to red (disconnect them)\n",
    "        for (grid_y, grid_x), idx in pos_to_index.items():\n",
    "            if grid[grid_y, grid_x] == 0 and labeled_grid[grid_y, grid_x] != largest_blue_label:\n",
    "                refined_labels[idx] = 1  # Change to red to maintain connectivity\n",
    "\n",
    "    return refined_labels\n",
    "\n",
    "def reconstruct_image_from_patches(image_shape, patches, positions, labels):\n",
    "    \"\"\"\n",
    "    Reconstruct an image from patches with color-coded overlay based on classification labels.\n",
    "\n",
    "    Args:\n",
    "        image_shape (tuple): The shape of the original image (H, W, C).\n",
    "        patches (np.array): Array of extracted patches.\n",
    "        positions (list): List of (y, x) coordinates for each patch.\n",
    "        labels (np.array): Classification labels for each patch (0: non-columnar, 1: columnar).\n",
    "\n",
    "    Returns:\n",
    "        reconstructed_image (np.array): Reconstructed image with color overlay.\n",
    "    \"\"\"\n",
    "    h, w, c = image_shape\n",
    "    patch_size = patches.shape[1]\n",
    "    reconstructed_image = np.zeros((h, w, c), dtype=np.uint8)\n",
    "    count_map = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "    # Color mapping for labels\n",
    "    columnar_color = np.array([255, 0, 0], dtype=np.uint8)   # Red for columnar\n",
    "    non_columnar_color = np.array([0, 0, 255], dtype=np.uint8)  # Blue for non-columnar\n",
    "\n",
    "    # for patch, (y, x), label in zip(patches, positions, labels):\n",
    "    #     color_overlay = columnar_color if label == 1 else non_columnar_color\n",
    "\n",
    "    #     # Blend original patch with label color overlay\n",
    "    #     blended_patch = (0.5 * patch + 0.5 * color_overlay).astype(np.uint8)\n",
    "\n",
    "    #     # Assign patch to the reconstructed image\n",
    "    #     reconstructed_image[y:y+patch_size, x:x+patch_size] += blended_patch\n",
    "    #     count_map[y:y+patch_size, x:x+patch_size] += 1\n",
    "\n",
    "    # # Normalize overlapping areas by averaging\n",
    "    # mask = count_map > 0\n",
    "    # reconstructed_image[mask] //= count_map[mask, None]\n",
    "\n",
    "    for (y, x), label in zip(positions, labels):\n",
    "        color = columnar_color if label == 1 else non_columnar_color\n",
    "\n",
    "        # Fill patch region with the respective color\n",
    "        reconstructed_image[y:y+patch_size, x:x+patch_size] = color\n",
    "\n",
    "    return reconstructed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update labels based on surrounding patches\n",
    "refined_labels = refine_patch_labels(image.shape, 64, patchposition, prediction)\n",
    "\n",
    "# Use the refined labels to reconstruct the image\n",
    "refined_image = reconstruct_image_from_patches(image.shape, patch, patchposition, refined_labels)\n",
    "cv2.imwrite(\"/home/yec23006/projects/research/KneeGrowthPlate/Embedding/results/patch_extraction/Postprocessing_8.png\", refined_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e676f69d41973115ac5d0906d285efc3ae427e1ab9693b2f8c22f7eccf693662"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
