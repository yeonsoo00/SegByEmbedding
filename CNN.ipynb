{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_extractor(img, num_patches=100, patch_size=64, intensity_threshold=10):\n",
    "    h, w, _ = img.shape\n",
    "    patches = []\n",
    "\n",
    "    for _ in range(num_patches):\n",
    "        y= np.random.randint(0, h - patch_size + 1)\n",
    "        x= np.random.randint(0, w - patch_size + 1)\n",
    "        patch = img[y:y+patch_size, x:x+patch_size, :]\n",
    "\n",
    "        if np.mean(patch) > intensity_threshold :\n",
    "            patches.append(patch)\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "\n",
    "def reconstruct_image_from_patches(image_shape, patches, positions, labels):\n",
    "    \"\"\"\n",
    "    Reconstruct an image from patches with color-coded overlay based on classification labels.\n",
    "\n",
    "    Args:\n",
    "        image_shape (tuple): The shape of the original image (H, W, C).\n",
    "        patches (np.array): Array of extracted patches.\n",
    "        positions (list): List of (y, x) coordinates for each patch.\n",
    "        labels (np.array): Classification labels for each patch (0: non-columnar, 1: columnar).\n",
    "\n",
    "    Returns:\n",
    "        reconstructed_image (np.array): Reconstructed image with color overlay.\n",
    "    \"\"\"\n",
    "    h, w, c = image_shape\n",
    "    patch_size = patches.shape[1]\n",
    "    reconstructed_image = np.zeros((h, w, c), dtype=np.uint8)\n",
    "    count_map = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "    # Color mapping for labels\n",
    "    columnar_color = np.array([255, 0, 0], dtype=np.uint8)   # Red for columnar\n",
    "    non_columnar_color = np.array([0, 0, 255], dtype=np.uint8)  # Blue for non-columnar\n",
    "\n",
    "    for (y, x), label in zip(positions, labels):\n",
    "        color = columnar_color if label >= 0.5 else non_columnar_color\n",
    "\n",
    "        # Fill patch region with the respective color\n",
    "        reconstructed_image[y:y+patch_size, x:x+patch_size] = color\n",
    "\n",
    "    return reconstructed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images & patches (ref/val)\n",
    "path2img = '/home/yec23006/projects/research/KneeGrowthPlate/Knee_GrowthPlate/Images/CCC_K05_hK_FL1_s1_shift3_So.jpg'\n",
    "path2platemask = '/home/yec23006/projects/research/KneeGrowthPlate/Embedding/results/plate_selection/growthplate_mask.png'\n",
    "path2columnar = '/home/yec23006/projects/research/KneeGrowthPlate/Embedding/results/plate_selection/columnar_mask.png'\n",
    "path2patch = \"/home/yec23006/projects/research/KneeGrowthPlate/Embedding/results/patch_extraction/filtered_patches_nb.npy\"\n",
    "path2patchposition = \"/home/yec23006/projects/research/KneeGrowthPlate/Embedding/results/patch_extraction/filtered_patch_positions_nb.npy\"\n",
    "save2 = \"/home/yec23006/projects/research/KneeGrowthPlate/Embedding/results/patch_extraction\"\n",
    "\n",
    "image = cv2.imread(path2img, cv2.IMREAD_COLOR)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "filtered_patches = np.load(path2patch) # for validation\n",
    "patchposition = np.load(path2patchposition) # for recon\n",
    "\n",
    "# ref patches (labels)\n",
    "columnar = image[6900:7050, 5100:5500, :]\n",
    "noncolumnar = image[6700:6850, 5100:5500]\n",
    "columnar_patches = patch_extractor(columnar)\n",
    "noncolumnar_patches = patch_extractor(noncolumnar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor dataset for train and test\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# TrainLoader\n",
    "all_patches = np.vstack((columnar_patches, noncolumnar_patches)).astype(np.float32)/255.0\n",
    "labels = np.array([1]*len(columnar_patches) + [0]*len(noncolumnar_patches)) # 1 for columnar, 0 for noncolumnar\n",
    "train_loader = torch.tensor(all_patches).permute(0,3,1,2).to(device)\n",
    "labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "data_loader = DataLoader(TensorDataset(train_loader, labels), batch_size=32, shuffle=True)\n",
    "\n",
    "# TestLoader\n",
    "test_images = torch.tensor(filtered_patches.astype(np.float32)/255.0).to(device)\n",
    "test_images = test_images.permute(0, 3, 1, 2)\n",
    "test_loader = DataLoader(TensorDataset(test_images), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 64, 64]), torch.Size([8, 3, 64, 64]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape, images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 72.50%\n",
      "Train Accuracy : 92.50%\n",
      "Train Accuracy : 81.50%\n",
      "Train Accuracy : 88.50%\n",
      "Train Accuracy : 95.50%\n",
      "Train Accuracy : 97.50%\n",
      "Train Accuracy : 98.00%\n",
      "Train Accuracy : 98.00%\n",
      "Train Accuracy : 99.00%\n",
      "Train Accuracy : 99.50%\n"
     ]
    }
   ],
   "source": [
    "# CNN patch classifier \n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 16 * 16, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "model = CNNClassifier().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.float().to(device).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f\"Train Accuracy : {train_accuracy:.2f}%\")\n",
    "    \n",
    "# Eval\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = batch[0].to(device)  # Extract the batch tensor\n",
    "        output = model(batch)  # Get model predictions\n",
    "        predictions.append(output.cpu().numpy())  # Move to CPU & store\n",
    "\n",
    "# Concatenate all batch predictions\n",
    "predictions = np.vstack(predictions)\n",
    "\n",
    "# Save predictions\n",
    "np.save(os.path.join(save2, \"CNNPatchClassifierPred.npy\"), predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.load(os.path.join(save2, \"CNNPatchClassifierPred.npy\"))\n",
    "reconstructed_image = reconstruct_image_from_patches(image.shape, filtered_patches, patchposition, predictions)\n",
    "overlay_img = reconstructed_image * 0.5 + image.astype(np.float32)\n",
    "overlay_img = np.clip(overlay_img, 0, 255).astype(np.uint8)\n",
    "Image.fromarray(overlay_img).save(os.path.join(save2, \"CNNPatchClassifierResultRecon.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e676f69d41973115ac5d0906d285efc3ae427e1ab9693b2f8c22f7eccf693662"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
